{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from operator import itemgetter   \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../data/raw/articles.txt', 'r', encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#articles.txt is a file containing article records, one record per row, column definition is:\n",
    "columns = [\"pubId\", \"is_hourly\", \"seqId\", \"on_homepage\", \"canonicalUrl\",\n",
    "                   \"firstScrape\", \"lang_iso\", \"lang_reliability\", \"title\", \"text\"]\n",
    "articles_dt = file.read().split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubId, canonicalUrl,firstScrape,title,text,lang_reliability = [],[],[],[],[],[]\n",
    "for article in articles_dt:    \n",
    "    row = article.split('\\t')\n",
    "    pubId.append(row[0])\n",
    "    canonicalUrl.append(row[4])\n",
    "    firstScrape.append(row[5])\n",
    "    lang_reliability.append(row[7])\n",
    "    title.append(row[8])\n",
    "    text.append(row[9])\n",
    "articles_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['pubId'], articles_df['canonicalUrl'], articles_df['firstScrape'], articles_df['title'], articles_df['text'], articles_df['lang_reliability']= pubId, canonicalUrl,firstScrape,title,text,lang_reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213605, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211577, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exclude the lang_reliability = 0 which the detected language is not reliable\n",
    "articles_df = articles_df[articles_df['lang_reliability'] == '1']\n",
    "articles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf 1-gram\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "feature_names = []\n",
    "def tfidf1(text):\n",
    "    try :\n",
    "        if '###' in text:\n",
    "            text = text.split('###')\n",
    "            vectorizer = TfidfVectorizer(stop_words = 'english',max_features = 100)\n",
    "            X = vectorizer.fit_transform(text)\n",
    "            feature_names.append(vectorizer.get_feature_names())\n",
    "    except:\n",
    "        print(text)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf 2-gram\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "feature_names2 = []\n",
    "def tfidf2(text):\n",
    "    try :\n",
    "        if '###' in text:\n",
    "            text = text.split('###')\n",
    "            vectorizer = TfidfVectorizer(ngram_range =(1,2), stop_words = 'english',max_features = 100)\n",
    "            X = vectorizer.fit_transform(text)\n",
    "            feature_names2.append(vectorizer.get_feature_names())\n",
    "    except:\n",
    "        print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' More from']\n",
      "[' ', ' 1']\n",
      "['Y ', ' Z']\n",
      "[' ', ' «']\n",
      "[' ', ' «']\n"
     ]
    }
   ],
   "source": [
    "#sub_articles_df= articles_df.sample(n=1000)\n",
    "articles_df['text'] = articles_df['text'].apply(tfidf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-333156ef565a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_names' is not defined"
     ]
    }
   ],
   "source": [
    "feature_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(feature_names).to_csv(\"../data/embedding/tfidf1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' More from']\n",
      "[' ', ' 1']\n",
      "['Y ', ' Z']\n",
      "[' ', ' «']\n",
      "[' ', ' «']\n"
     ]
    }
   ],
   "source": [
    "articles_df['text'] = articles_df['text'].apply(tfidf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01',\n",
       " '19',\n",
       " '19 2018',\n",
       " '2018',\n",
       " '2018 01',\n",
       " '2018 49',\n",
       " '49',\n",
       " 'advantage',\n",
       " 'advantage long',\n",
       " 'agency',\n",
       " 'agency review',\n",
       " 'ago',\n",
       " 'alphabet',\n",
       " 'antitrust',\n",
       " 'awaited',\n",
       " 'billion',\n",
       " 'budget',\n",
       " 'comments',\n",
       " 'eu',\n",
       " 'european',\n",
       " 'european union',\n",
       " 'fine',\n",
       " 'google',\n",
       " 'government',\n",
       " 'jul',\n",
       " 'jul 19',\n",
       " 'long',\n",
       " 'manufacturers',\n",
       " 'manufacturers failure',\n",
       " 'match',\n",
       " 'match european',\n",
       " 'mid',\n",
       " 'mid october',\n",
       " 'mitchell',\n",
       " 'mitchell waged',\n",
       " 'mobile',\n",
       " 'mobile devices',\n",
       " 'nato',\n",
       " 'nato summit',\n",
       " 'neil',\n",
       " 'neil mitchell',\n",
       " 'netherlands',\n",
       " 'netherlands kicks',\n",
       " 'new',\n",
       " 'new ftc',\n",
       " 'october',\n",
       " 'october stop',\n",
       " 'ordered',\n",
       " 'ordered change',\n",
       " 'owned',\n",
       " 'owned bank',\n",
       " 'parent',\n",
       " 'parent alphabet',\n",
       " 'paying',\n",
       " 'paying fair',\n",
       " 'penalty',\n",
       " 'penalty equal',\n",
       " 'phoenix',\n",
       " 'phoenix capita',\n",
       " 'phrased',\n",
       " 'planning',\n",
       " 'planning trillion',\n",
       " 'practices',\n",
       " 'practices eu',\n",
       " 'precede',\n",
       " 'precede european',\n",
       " 'president',\n",
       " 'president jean',\n",
       " 'president trump',\n",
       " 'probe',\n",
       " 'probe google',\n",
       " 'punishment',\n",
       " 'punishment dished',\n",
       " 'rbs',\n",
       " 'rbs hbos',\n",
       " 'realdonaldtrump',\n",
       " 'realdonaldtrump july',\n",
       " 'record',\n",
       " 'record 3bn',\n",
       " 'record fine',\n",
       " 'regulators',\n",
       " 'regulators bailed',\n",
       " 'response',\n",
       " 'response brussels',\n",
       " 'result',\n",
       " 'result fine',\n",
       " 'revenue',\n",
       " 'review',\n",
       " 'review eu',\n",
       " 'russia',\n",
       " 'russia comments',\n",
       " 'slapped',\n",
       " 'taken',\n",
       " 'taken advantage',\n",
       " 'told',\n",
       " 'trump',\n",
       " 'uk',\n",
       " 'union',\n",
       " 'wednesday',\n",
       " 'year']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(feature_names2).to_csv(\"../data/embedding/tfidf2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
