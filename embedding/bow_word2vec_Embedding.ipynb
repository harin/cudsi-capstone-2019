{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('articles.txt', 'r', encoding = 'utf8')\n",
    "columns = [\"pubId\", \"is_hourly\", \"seqId\", \"on_homepage\", \"canonicalUrl\",\n",
    "                   \"firstScrape\", \"lang_iso\", \"lang_reliability\", \"title\", \"text\"]\n",
    "articles_dt = file.read().split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubId, is_hourly, seqId, on_homepage, canonicalUrl,firstScrape,lang_iso, lang_reliability, title,text = [],[],[],[],[], [],[],[],[],[]\n",
    "for article in articles_dt:    \n",
    "    row = article.split('\\t')\n",
    "    pubId.append(row[0])\n",
    "    is_hourly.append(row[1])\n",
    "    seqId.append(row[2])\n",
    "    on_homepage.append(row[3])\n",
    "    canonicalUrl.append(row[4])\n",
    "    firstScrape.append(row[5])\n",
    "    lang_iso.append(row[6])\n",
    "    lang_reliability.append(row[7])\n",
    "    title.append(row[8])\n",
    "    text.append(row[9])\n",
    "articles_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['pubId'], articles_df['is_hourly'], articles_df['seqId'], articles_df['on_homepage'], articles_df['canonicalUrl'], articles_df['firstScrape'], articles_df['lang_iso'], articles_df['lang_reliability'],articles_df['title'], articles_df['text'] = pubId, is_hourly, seqId, on_homepage, canonicalUrl,firstScrape,lang_iso, lang_reliability, title,text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213605, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'by Phoenix Capita… - Jul 19, 2018 8:49 am ### The Government is planning a $1 trillion deficit next year. ### Jul 19, 2018 8:49 AM ### Financial Terrorism In The UK – Collusion between Government, Regulators & Two Bailed-Out UK Banks ### by GoldCore - Jul 19, 2018 8:01 am ### Neil Mitchell has waged a long battle for justice for UK victims of the UK taxpayer owned bank RBS and HBOS ### Jul 19, 2018 8:01 AM ### 0 ### SHARES ### In a move that many had expected, President Trump lashed out over Twitter in response to Brussels\\' decision to slap Google with an record €4.3bn ($5 billion) antitrust fine, exclaiming \"I told you so!\" before suggesting that the move was further evidence that the EU had \"taken advantage of the U.S., but not for long!\" ### I told you so! The European Union just slapped a Five Billion Dollar fine on one of our great companies, Google. They truly have taken advantage of the U.S., but not for long! ### — Donald J. Trump (@realDonaldTrump) July 19, 2018 ### On Wednesday, in a long-awaited move, Google parent Alphabet was slapped with the record fine and ordered to change the way it installs search and web browser apps onto Android mobile devices. The company was given until mid-October to stop the \"illegal practices\" as the EU phrased it, on their contracts with handset manufacturers. Failure to comply will result in a 5% fine on revenue. ### The penalty, which is equal to the amount the Netherlands kicks into the EU budget each year, is higher than any other punishment dished out by the US, Chinese or other antitrust authorities - while the US is unlikely to match the European Union\\'s fine. ### While new FTC Chairman Joseph Simons told Congress on Wednesday that the agency will review the EU findings closely - the same agency ended a similar probe of Google several years ago. ### President Trump\\'s comments precede European Commission president Jean-Claude Juncker\\'s visit to Washington next week amid heightened tensions over trade and Russia. The comments also follow a contentious NATO summit where Trump derided EU countries for not paying their fair share of the budget. ### Tags'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(articles_df.shape)\n",
    "articles_df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211577, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exclude the lang_reliability = 0 which the detected language is not reliable\n",
    "articles_df = articles_df[articles_df['lang_reliability'] == '1']\n",
    "articles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## text normzalization\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a paragrapy\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"[^\\w\\s]\", '', text) ## Remove all non-word characters (everything except numbers and letters)\n",
    "    text = text.lower() # lowercase text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwords from text\n",
    "    return text\n",
    "    \n",
    "articles_df['text'] = articles_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phoenix capita jul 19 2018 849 government planning 1 trillion deficit next year jul 19 2018 849 financial terrorism uk collusion government regulators two bailedout uk banks goldcore jul 19 2018 801 neil mitchell waged long battle justice uk victims uk taxpayer owned bank rbs hbos jul 19 2018 801 0 shares move many expected president trump lashed twitter response brussels decision slap google record 43bn 5 billion antitrust fine exclaiming told suggesting move evidence eu taken advantage us long told european union slapped five billion dollar fine one great companies google truly taken advantage us long donald j trump realdonaldtrump july 19 2018 wednesday longawaited move google parent alphabet slapped record fine ordered change way installs search web browser apps onto android mobile devices company given midoctober stop illegal practices eu phrased contracts handset manufacturers failure comply result 5 fine revenue penalty equal amount netherlands kicks eu budget year higher punishment dished us chinese antitrust authorities us unlikely match european unions fine new ftc chairman joseph simons told congress wednesday agency review eu findings closely agency ended similar probe google several years ago president trumps comments precede european commission president jeanclaude junckers visit washington next week amid heightened tensions trade russia comments also follow contentious nato summit trump derided eu countries paying fair share budget tags'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['title'] = articles_df['title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'told trump hits eu 5 billion google fine zero hedge'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df['title'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bag of word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. uni-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = []\n",
    "for i in articles_df.index:\n",
    "    comb.append(articles_df['title'][i] + ' ' + articles_df['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "text_counts= cv.fit_transform(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211577, 825770)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(text_counts[0,:].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save result\n",
    "np.save('BagOfWord_output.npy', text_counts)    # .npy extension is added if not given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved result\n",
    "#test = np.load('BagOfWord_output.npy', allow_pickle=True)\n",
    "#np.asmatrix(test)[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. bi-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer(ngram_range=(2, 2))\n",
    "text_counts2= cv2.fit_transform(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211577, 13000246)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counts2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('BagOfWord2_output.npy', text_counts)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec,KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'told trump hits eu 5 billion google fine zero hedge'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comb.index = range(0,len(comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(text): \n",
    "    article_vect = np.empty([len(text), 300])\n",
    "    for i in range(0,len(text)):\n",
    "        word_list = text[i].split(' ')\n",
    "        for word in word_list:\n",
    "            total_vec = np.zeros(300)\n",
    "            if word in model:\n",
    "                vec = model[word]\n",
    "                total_vec = total_vec + vec\n",
    "        article_vect[i,:] = total_vec/len(word_list)\n",
    "    return article_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_vect = word2vec(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211577, 300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
